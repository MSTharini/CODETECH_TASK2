import speech_recognition as sr

def recognize_speech_from_microphone():
    # Initialize recognizer
    recognizer = sr.Recognizer()

    # Use the microphone as the audio source
    with sr.Microphone() as source:
        print("Please speak now...")
        recognizer.adjust_for_ambient_noise(source)  # Adjust for ambient noise
        audio = recognizer.listen(source)

    try:
        # Use Google Web Speech API to transcribe the audio
        print("Transcribing speech...")
        text = recognizer.recognize_google(audio)  # Recognize speech using Google's API
        print("You said: ", text)
        return text
    except sr.UnknownValueError:
        print("Sorry, I could not understand the audio.")
    except sr.RequestError as e:
        print(f"Could not request results; {e}")

# Call the function to test it
if __name__ == "__main__":
    recognize_speech_from_microphone()

import torch
from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC
import librosa

def recognize_speech_with_wav2vec2(audio_path):
    # Load the pre-trained Wav2Vec 2.0 model and processor
    processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")
    model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-base-960h")

    # Load the audio file using librosa
    audio_input, _ = librosa.load(audio_path, sr=16000)  # Ensure 16kHz sampling rate

    # Process the audio to match the model input format
    inputs = processor(audio_input, return_tensors="pt", sampling_rate=16000)

    # Perform speech-to-text using the model
    with torch.no_grad():
        logits = model(input_values=inputs.input_values).logits

    # Decode the logits to get the predicted transcription
    predicted_ids = torch.argmax(logits, dim=-1)
    transcription = processor.decode(predicted_ids[0])
    
    return transcription

# Test the function with an audio file
if __name__ == "__main__":
    audio_path = "path_to_your_audio_file.wav"  # Provide the path to your audio file
    transcription = recognize_speech_with_wav2vec2(audio_path)
    print(f"Transcription: {transcription}")
